{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Regresión Lineal.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOSSycVh/y8xohiikOvpaUj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Hm5qQ1v8dWnK","executionInfo":{"status":"ok","timestamp":1643399919528,"user_tz":300,"elapsed":1227,"user":{"displayName":"Daniel Esposito","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijcImd9IcOXDxaARINmgLZUWy4FC1qKuIx6nYxgw=s64","userId":"05566080164699410435"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression\n","import scipy"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"sY4UdsB-eavg","executionInfo":{"status":"ok","timestamp":1643399919529,"user_tz":300,"elapsed":3,"user":{"displayName":"Daniel Esposito","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijcImd9IcOXDxaARINmgLZUWy4FC1qKuIx6nYxgw=s64","userId":"05566080164699410435"}}},"source":["X = np.array([6, 7, 11, 15, 18, 21, 23, 29, 31, 37, 39])\n","y = np.array([29, 23, 29, 14, 21, 25, 7, 7, 13, 0, 3])\n","\n","np.random.seed(1111)\n","# Definir semilla de aleatoriedad para reproducibilidad del experimiento\n","\n","n_muestras = X.shape[0]\n","#Número de muestra"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ois5s2UnJ9lt"},"source":["Implementación propia de algoritmo de Regresión Lineal"]},{"cell_type":"code","metadata":{"id":"YWMnBZi-fHt7","executionInfo":{"status":"ok","timestamp":1643399919770,"user_tz":300,"elapsed":243,"user":{"displayName":"Daniel Esposito","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijcImd9IcOXDxaARINmgLZUWy4FC1qKuIx6nYxgw=s64","userId":"05566080164699410435"}}},"source":["def calcular_regresión_lineal(X, y, tasa_aprendizaje=0.001, max_iter=1000000):\n","    X = X.reshape(-1, 1)\n","    y = y.reshape(-1, 1)\n","\n","    pendiente = 0\n","    intersección = 0\n","\n","    #Por cada iteración\n","    for iteración in range(max_iter):\n","\n","        #Obtener aproximación del modelo\n","        aproximación = np.dot(X, pendiente) + intersección\n","\n","        # Obtener Gradientes\n","        dw = 1/(n_muestras) * np.dot(X.T, (aproximación - y))\n","        db = 1/(n_muestras) * np.sum(aproximación - y)\n","\n","        # Aplicar técnica del descenso de la gradiente\n","        pendiente -= tasa_aprendizaje * dw\n","        intersección -= tasa_aprendizaje * db\n","    return pendiente, intersección\n","\n","def predecir(X, y, predicción):\n","    #Función para predecir y graficar\n","    plt.scatter(X, y)\n","    plt.plot(X, predicción, 'r')\n","\n","def error_estándar(predicción, y):\n","    #Calcular error estándar\n","    n = predicción.shape[0]\n","    total = np.sum(np.square(predicción - y))\n","    deviación_estándar = np.sqrt(total / n-1)\n","    error_estándar = deviación_estándar / np.sqrt(n)\n","    print(f\"Error Estándar = {error_estándar}\")\n","\n","def coeficiente_correlación(X, y):\n","    #Calcular coeficiente de correlación\n","    covarianza = np.sum((X - np.mean(X)) * (y - np.mean(y))) / X.shape[0]\n","    X_std = np.std(X)\n","    y_std = np.std(y)\n","\n","    correlación = covarianza / (X_std * y_std)\n","    print(f\"Coeficiente de Correlación = {correlación}\")"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1dflKc4pvR4u"},"source":["El algoritmo de regresión lineal es dado por la fórmula $\\hat{y}=\\beta_0 + \\beta_1X$ donde:\n","* $\\hat{y}$ es la variable dependiente a estimar\n","* $X$ es la variable independiente en la posición\n","* $\\beta_0$ es el sesgo o intersección\n","* $\\beta_1$ es la pendiente \n","\n","Según Steven C. Chapra (2010) la regresión lineal consiste en obtener una función de aproximación que se ajuste a la forma o a la tendencia general de los datos, sin coincidir necesariamente en todos los puntos. Donde se utiliza una línea recta para caracterizar de manera general la tendencia de los datos sin pasar a través de algún punto específico.\n","\n","Nótese que $\\hat{y}$ es el resultado de una función donde el dominio está representado por la variable independiente $X$, y los valores $\\beta_0$ y $\\beta_1$ son parámetros que el modelo debe estimar, dicha estimación se basa en el criterio de los mínimos cuadrados. \n","\n","Afirma Raymond (2010) que \"Una estrategia para ajustar una mejor línea a través de los datos será minimizar la suma de los errores residuales de todos los datos disponibles, el cual es dado por la fórmula $e=\\sum_{i=1}^{n} (\\hat{y}_i-y_i)^2$ o en su defecto $e=\\sum_{i=1}^{n} ((\\beta_0 + \\beta_1X_i)-y_i)^2$. Este criterio tiene varias ventajas, entre ellas el hecho de que se obtiene una línea única para cierto conjunto de datos.\"\n","\n","La manera en la cual los parámetros del modelo se ajustan de manera iterativa al conjunto de datos con base a la función de pérdida $e$ es, entre muchas otras técnicas, el descenso de la gradiente.\n","\n","Menciona Raymond (2010) que \"para determinar los valores $\\beta_0$ y $\\beta_1$ se deriva la función de pérdida $e$ con respecto a cada uno de los coeficientes\". Dicha gradiente apunta hacia la dirección del ascenso más inclinado de la función multivariada, dado que lo que se requiere es minimizar la función de pérdida, se debe ajustar la gradiente para que apunte hacia el descenso más inclinado, esto se consigue aplicando la gradiente para actualizar los parámetros de la siguiente forma: $\\beta = \\beta - \\alpha\\nabla$ donde $\\nabla = \\frac{\\partial e}{\\partial x}$ y $α$ conocido como tasa de aprendizaje es un parámetro arbitrario o **HIPERPARÁMETRO**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"cOCtSbNVh4ta","executionInfo":{"status":"ok","timestamp":1643399944089,"user_tz":300,"elapsed":24321,"user":{"displayName":"Daniel Esposito","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijcImd9IcOXDxaARINmgLZUWy4FC1qKuIx6nYxgw=s64","userId":"05566080164699410435"}},"outputId":"4ac73e5b-53d5-42c0-fc4e-3425fa3a85f2"},"source":["X = X.reshape(-1, 1)\n","y = y.reshape(-1, 1)\n","\n","pendiente, intersección = calcular_regresión_lineal(X, y)\n","#Estimación de parámetros\n","predicción = np.dot(X, pendiente) + intersección\n","#Predecir\n","error_estándar(predicción, y)\n","predecir(X, y, predicción)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Error Estándar = 1.4803884788144295\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"0g6agIARjiO6"},"source":["El error estándar según Jerome Friedman (2008) el error estándar del estimado cuantifica la dispersión alrededor de la linea de regresión, y se utiliza para cuantificar la “bondad” de nuestro ajuste, esto es en particular útil para comparar diferentes regresiones.\n","\n","el error estándar es dado por la fórmula $\\frac{DE}{\\sqrt{n}}$ donde $DE$ es la deviación estándar de las predicciones y es dado por la fórmula $\\sqrt\\frac{\\sum_{i=1}^{n} (\\hat{y_i} - y)^2}{n-1}$."]},{"cell_type":"markdown","metadata":{"id":"7DRp531VpIcX"},"source":["Afirma Patrick Schober (2018) que \"El coeficiente de correlación es usualmente dado por el símbolo $r$ y oscila entre $-1$ y $+1$. Un coeficiente de correlación cerca de $0$, implica una ausencia de relación entre las dos variables. Un coeficiente de correlación cerca de $1$, implica una relación positiva entre las dos variables, lo que significa que, el incremento en una variable está asociado con el incremento de la otra. Un coeficiente de correlación cerca de $-1$ indica una correlación negativa entre ambas variables, el incremento de una variable está asociado con la reducción de la otra variable\".\n","\n","El coeficiente de correlación está dado por la fórmula $ r = \\frac{cov(x, y)}{(\\sigma_x\\sigma_y)}$ donde:\n","\n","* $cov(x,y)$ es la covarianza entre las variables y se calcula mediante: $\\frac{\\sum_{i=1}^{N}(x_i-\\overline{x})(y_i-\\overline{y})}{N}$ donde $\\overline{x}$ y $\\overline{y}$ son los promedios de cada variable y ${x_i}{y_i}$ son los puntos de datos en el índice $i$\n","\n","* $\\sigma_x$ y $\\sigma_y$ son la deviación estándar para cada variable"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoRqiIohJ7-L","executionInfo":{"status":"ok","timestamp":1643399944090,"user_tz":300,"elapsed":16,"user":{"displayName":"Daniel Esposito","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijcImd9IcOXDxaARINmgLZUWy4FC1qKuIx6nYxgw=s64","userId":"05566080164699410435"}},"outputId":"72375f19-aace-4f22-bd1f-0c519ce6f53f"},"source":["coeficiente_correlación(X, y)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Coeficiente de Correlación = -0.8641730380309871\n"]}]},{"cell_type":"markdown","metadata":{"id":"bJ47j7afwDy0"},"source":["Podemos observar que el coeficiente de correlación es negativo, lo que indica una relación descendente entre ambas variables, dicho fenómeno es observable al graficar los datos y, mediante el algoritmo de regresión lineal, puede determinarse que con el aumento de una variable, la otra disminuye"]},{"cell_type":"markdown","metadata":{"id":"awpVm3BuxLU1"},"source":["Fuentes bibliográficas:\n","\n","Steve C. Chapra, Raymond P. Canale, Métodos numéricos para ingenieros, Edición N°5, 2010\n","\n","Jerome Friedman, Trevor Hastie ,Robert Tibshirani, Elements of Statistical Learning, Edición N°2, 2008\n","\n","Patrick Schober, Christa Boer, Correlation Coefficients: Appropriate Use and Interpretation, Edición Única, 2018"]}]}